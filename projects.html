<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Projects</title>
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" type="text/css" href="https://gongzhitaao.org/orgcss/org.css"/>
<link rel="stylesheet" type="text/css" href="/orgstyle.css"/>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Fira+Mono:wght@400;700&amp;display=swap" rel="stylesheet">
<!-- <link rel="icon" href="spock-favicon.png" type="image/png"> -->
</head>
<body>
<div id="preamble" class="status">
<hr style="border-top: 1px solid black;">
<div class='topnav' style='display: flex; justify-content: space-between; align-items: center;'>
  <a href="/index.html"><h2 style='margin-top: 0; margin-bottom: 0; margin-left:0px;'>Lafith Mattara</h2></a>
  <div class='topnav2' style='color:#cfcaca;'>
   / <a href='/blog.html' style='font-weight:bold; font-style:bold;'>Blog</a> 
   / <a href='/projects.html' style='font-weight:bold; font-style:bold;'>Projects</a>  
   / <a href='/now.html' style='font-weight:bold; font-style:bold;'>Now</a>  
  </div>
</div>
<hr style="border-top: 1px solid black;">
</div>
<div id="content" class="content">

<div id="outline-container-org42fab00" class="outline-2">
<h2 id="org42fab00">Real-Time Self-Prompting Adaptation of a Foundation Model for Fetal Ultrasound</h2>
<div class="outline-text-2" id="text-org42fab00">
<p>
Adapted the Segment Anything (SAM) foundation model to be self-prompting for fetal ultrasound, achieving clinical-grade precision with 96% specificity and an inference time of just 12 ms per image. Deployed in a robotic prototype, the system reduced manual scanning time from 30–45 minutes to 4 minutes—an 85%+ efficiency improvement—enabling high-throughput prenatal screening and drawing strong interest from clinicians at the XVIII Clinical Ultrasonography in Practice (CUSP) conference.
</p>


<figure id="orgb014191">
<img src="./posts/figures/cusp_ai_assistance.gif" alt="cusp_ai_assistance.gif">

</figure>


<figure id="orge3a2313">
<img src="./posts/figures/cusp_robot.jpg" alt="cusp_robot.jpg" width="600px">

</figure>
</div>
</div>

<div id="outline-container-org5dbc457" class="outline-2">
<h2 id="org5dbc457">Deep Learning-Based Analysis of Breast Cancer Whole Slide Images</h2>
<div class="outline-text-2" id="text-org5dbc457">
<p>
Developed convolutional and graph neural networks to analyze breast cancer whole slide images, enabling automated interpretation and patch-level annotation with high accuracy (F1 score of 0.95 across 24 classes). This work also explored links between neighborhood deprivation, tumor microenvironment, and race, with findings presented at two research symposia.
</p>


<figure id="orgb47ce41">
<img src="./media/uab.png" alt="uab.png">

</figure>
</div>
</div>

<div id="outline-container-orgc0adab7" class="outline-2">
<h2 id="orgc0adab7">Stereo-Endoscope VR System for Real-Time Medical Visualization</h2>
<div class="outline-text-2" id="text-orgc0adab7">
<p>
Designed and built a complete VR application for real-time visualization of stereo-endoscope video streams, integrating video capture, image processing, and 3D rendering. The system was showcased at MEDICA 2024, highlighting its innovation in medical imaging and interactive visualization.
</p>


<figure id="org2511f5d">
<img src="./media/endovr.png" alt="endovr.png">

</figure>
</div>
</div>

<div id="outline-container-orga6850fa" class="outline-2">
<h2 id="orga6850fa">Contrast Enhancement of Industrial CT Scans Using Multi-Scale Image Processing</h2>
<div class="outline-text-2" id="text-orga6850fa">
<p>
Enhanced contrast in industrial CT scans using multi-scale image processing techniques. This revealed subtle internal structures, improving clarity for inspection and analysis.
</p>


<figure id="orga4a48c3">
<img src="./media/contrast.png" alt="contrast.png">

</figure>
</div>
</div>

<div id="outline-container-orgbcdee3f" class="outline-2">
<h2 id="orgbcdee3f">Autonomous Underwater Vehicle Simulator</h2>
<div class="outline-text-2" id="text-orgbcdee3f">
<p>
A 3D underwater simulation environment built in Unity to model the dynamics and control of an Autonomous Underwater Vehicle (AUV). It enables realistic testing of navigation and control algorithms in a virtual underwater setting with support for simulated sensors. Designed for rapid prototyping and validation of AUV software stacks.
</p>

<p>
<b>Github Repo</b> : <a href="https://github.com/lafith/AUV-Simulator-Unity">AUV-Simulator-Unity</a>
</p>


<figure id="orgc09eec2">
<img src="./media/auv2.gif" alt="auv2.gif">

</figure>


<figure id="org080d66c">
<img src="./media/auv1.gif" alt="auv1.gif">

</figure>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="creator"><a href="https://www.gnu.org/software/emacs/">Emacs</a> 29.3 (<a href="https://orgmode.org">Org</a> mode 9.6.15)</p>
</div>
</body>
</html>
